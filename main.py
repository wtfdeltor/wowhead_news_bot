import feedparser
import requests
import os
from bs4 import BeautifulSoup
from datetime import datetime
import re
import html
import time

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHANNEL = os.getenv("TELEGRAM_CHANNEL")
NOOBCLUB_RSS = "https://www.noob-club.ru/rss2.xml"
HEADERS = {"User-Agent": "Mozilla/5.0"}

MAX_CAPTION_LENGTH = 1024
IV_HASH = "fed000eccaa3ad"
SEEN_LINKS_FILE = "seen_links.txt"
POST_DELAY_SECONDS = 0

def extract_preview(summary_html):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML –¥–æ —Å—Å—ã–ª–∫–∏ '–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ'"""
    match = re.search(r"(.*?)(<a\s+href=.*?>–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ</a>)", summary_html, re.DOTALL)
    if match:
        return match.group(1)
    return summary_html

def clean_html_preserve_spaces(html_text):
    """–û—á–∏—â–∞–µ—Ç HTML –æ—Ç —Ç–µ–≥–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤."""
    soup = BeautifulSoup(html_text, "html.parser")

    for br in soup.find_all("br"):
        br.replace_with("\n")

    for tag in soup.find_all("a"):
        tag.replace_with(tag.get_text())

    raw_text = soup.get_text(" ", strip=True)

    raw_text = raw_text.replace("quotquot", '').replace("&#039&#039", "'").replace("#039#039", "'")
    text = html.unescape(raw_text)

    # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    text = re.sub(r":cut:", "", text)
    text = re.sub(r"\s+([.,!?;:])", r"\1", text)
    text = re.sub(r"([.,!?;:])(?=\S)", r"\1 ", text)
    text = re.sub(r"\s+", " ", text).strip()

    # –ó–∞–º–µ–Ω–∞ –∫–∞–≤—ã—á–µ–∫ –∏ —Å–∏–º–≤–æ–ª–æ–≤ Unicode
    text = text.replace("\u201c", '"').replace("\u201d", '"').replace("\u2018", "'").replace("\u2019", "'")
    text = text.replace("&quot;", '"').replace("&#039;", "'").replace("#039", "'")

    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø–æ–¥—Ä—è–¥ –∏ –æ–±—Ä–∞–º–ª—è—é—â–∏—Ö –∫–∞–≤—ã—á–µ–∫, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏
    text = re.sub(r"\s*"([^"]*?)"\s*", r'"\1"', text)
    text = re.sub(r"\s*'([^']*?)'\s*", r"'\1'", text)

    return text

def has_been_posted(link):
    if not os.path.exists(SEEN_LINKS_FILE):
        return False
    with open(SEEN_LINKS_FILE, "r") as f:
        return link in f.read()

def mark_as_posted(link):
    with open(SEEN_LINKS_FILE, "a") as f:
        f.write(link + "\n")

def fetch_articles():
    print("üîÅ –ó–∞–≥—Ä—É–∂–∞–µ–º RSS-—Ñ–∏–¥ Noob Club...")
    response = requests.get(NOOBCLUB_RSS, headers=HEADERS)
    if response.status_code != 200:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ RSS: {response.status_code}")
        return []
    feed = feedparser.parse(response.content)
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(feed.entries)}")
    if not feed.entries:
        print("‚ùó RSS –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")
        return []

    new_articles = []
    for entry in reversed(feed.entries):
        if has_been_posted(entry.link):
            continue
        summary_html = entry.summary
        preview_html = extract_preview(summary_html)
        preview_text = clean_html_preserve_spaces(preview_html)
        new_articles.append({
            "title": entry.title,
            "link": entry.link,
            "published": entry.published,
            "preview": preview_text,
        })
    return new_articles

def build_instant_view_url(link):
    return f"https://t.me/iv?url={link}&rhash={IV_HASH}"

def post_to_telegram(title, iv_link, preview):
    caption = f"<b>{title}</b>\n{preview}\n<a href=\"{iv_link}\">\u200b</a>"
    if len(caption) > MAX_CAPTION_LENGTH:
        preview_cut = preview[:MAX_CAPTION_LENGTH - len(f"<b>{title}</b>\n<a href=\"{iv_link}\">\u200b</a>") - 5] + "..."
        caption = f"<b>{title}</b>\n{preview_cut}\n<a href=\"{iv_link}\">\u200b</a>"
    response = requests.post(
        f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
        data={
            "chat_id": TELEGRAM_CHANNEL,
            "text": caption,
            "parse_mode": "HTML",
            "disable_web_page_preview": False,
        },
    )
    print(f"üì§ –°—Ç–∞—Ç—É—Å –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {response.status_code}")
    if response.status_code == 200:
        print("‚úÖ –ü–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {response.json()}")

def main():
    articles = fetch_articles()
    if not articles:
        print("‚ö†Ô∏è –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –Ω–µ—Ç ‚Äî –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞.")
        return
    for idx, article in enumerate(articles):
        iv_link = build_instant_view_url(article["link"])
        post_to_telegram(article["title"], iv_link, article["preview"])
        mark_as_posted(article["link"])
        if idx < len(articles) - 1:
            print(f"‚è≥ –ñ–¥—ë–º {POST_DELAY_SECONDS} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –ø–æ—Å—Ç–æ–º...")
            time.sleep(POST_DELAY_SECONDS)

if __name__ == "__main__":
    main()
